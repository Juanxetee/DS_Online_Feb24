
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import pickle

from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

# CARGAR DATOS
df = sns.load_dataset('titanic')
df.drop('deck',axis=1,inplace=True)
print(df.head())

# FEATURE ENGINEERING
# Manejar valores faltantes
df['age'].fillna(df['age'].median(), inplace=True)
df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)
df['fare'].fillna(df['fare'].median(), inplace=True)
df['fare'] = np.log(df['fare']+1)
df = pd.get_dummies(df, columns=['sex', 'embarked','who'])

print()
print('Data Frame')
print(df.head())
print()


# SELECCIÓN FINAL DE FEATURES
features = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_male', 'embarked_Q', 'embarked_S','who_man','who_woman']
X = df[features]
y = df['survived']

# MINI-EDA
pairplot = sns.pairplot(data=df[features+['survived']], hue='survived',palette='Set1')
pairplot.savefig('Img/pairplot.png')

# TARGET
fig = plt.figure()
y.hist(bins=10)
fig.savefig('Img/target.png')

# VERBOSE
print()
print('Features')
print(X.head())
print()

# TRAIN-TEST SPLIT
# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_total = pd.concat([X_train,y_train])

# NORMALIZAR CARACTERÍSTICAS
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# MULTI-LAYER-PERCEPTRON CON KERAS
model = Sequential()
model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(16, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

# FIT
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f'Test Accuracy: {accuracy:.4f}')

# MÉTRICAS
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

# SALVAR MODELO
model.save('Models/titanic_predictor_model.h5')


# REPORTS PARA MLP
print()
print('Classification report for MLP')
report = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy del MLP:', accuracy_score)
print(report)
print(conf_matrix)
print()

plt.figure(figsize=(8, 6))
conf_matrix_rf = sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', 
            xticklabels=['Not Survived', 'Survived'], 
            yticklabels=['Not Survived', 'Survived'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.savefig('Img/conf_matrix_mlp.png')

# CLASIFICADOR TIPO RandomForestClassifier
print('GridSearch for RandomForestClassifier')
rf_model = RandomForestClassifier(random_state=42)

# Definir los hiperparámetros para la búsqueda en rejilla
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [ 5, 10, 20],
    'min_samples_leaf': [ 5,10, 40,100],
}

# GRIDSEARCHCV
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,
                           cv=5, n_jobs=-1, verbose=1, scoring='accuracy')

# FIT
grid_search.fit(X_train, y_train)

# MÉTRICAS
best_rf_model = grid_search.best_estimator_ # Hacer predicciones sobre el conjunto de prueba
y_pred = best_rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Accuracy: {accuracy}")
print("Classification Report:")
print(report)
print("Confusion Matrix:")
print(conf_matrix)
df.to_csv('Data/titanic.csv')
plt.figure(figsize=(8, 6))
conf_matrix_rf = sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', 
            xticklabels=['Not Survived', 'Survived'], 
            yticklabels=['Not Survived', 'Survived'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.savefig('Img/conf_matrix_rf.png')

# PERSISTIR EL MODELO
with open('Models/best_rf_model.pkl', 'wb') as f:
    pickle.dump(best_rf_model, f)

